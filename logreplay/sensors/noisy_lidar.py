import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import glob
import os.path as osp
import tqdm
from opencood.utils.pcd_utils import pcd_to_np, mask_points_by_range


class LidarDataset(Dataset):
    def __init__(self,
                 root,
                 split,
                 lidar_sem_dir,
                 lidar_range):
        self.root = root
        self.split = split
        self.sem_dir = lidar_sem_dir
        self.lidar_range = lidar_range
        scenarios = sorted(os.listdir(osp.join(root, split)))
        lidar_files = []
        for s in scenarios:
            lidar_files.extend(glob.glob(osp.join(root, split, s, '*/*.pcd')))
        self.lidar_files = sorted(lidar_files)

    def __len__(self):
        return len(self.lidar_files)

    def __getitem__(self, item):
        lidar_file = self.lidar_files[item]
        sample = self.load_one_sample(lidar_file)
        return sample

    def load_one_sample(self, lidar_file):
        file_info = lidar_file.split('/')
        scenario = file_info[-3]
        vid = file_info[-2]
        fn = file_info[-1]
        lidar_file = osp.join(self.root, self.sem_dir, scenario,
                              vid, fn.replace('.pcd', '_lidarcenter.bin'))
        lidar = np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)[:, :3]
        lidar = mask_points_by_range(lidar, self.lidar_range)
        lidar_sem_file = osp.join(self.root, self.sem_dir, scenario,
                                  vid, fn.replace('.pcd', '_semantic_lidarcenter.bin'))
        data = np.fromfile(lidar_sem_file, dtype=np.dtype([
            ('x', np.float32), ('y', np.float32), ('z', np.float32),
            ('CosAngle', np.float32), ('ObjIdx', np.uint32),
            ('ObjTag', np.uint32)]))
        lidar_sem = np.stack([data[k] for k in ['x', 'y', 'z', 'ObjTag']], axis=1)
        lidar_sem = mask_points_by_range(lidar_sem, self.lidar_range)

        # import matplotlib.pyplot as plt
        # fig = plt.figure()
        # ax = fig.add_subplot()
        # ax.plot(lidar[:, 0], lidar[:, 1], '.', markersize=1)
        # ax.plot(lidar_sem[:, 0], lidar_sem[:, 1], '.', markersize=1)
        # plt.show()
        # plt.close()

        return {
            'lidar': lidar,
            'lidar_sem': lidar_sem,
            'out_file': lidar_sem_file.replace('pcd', 'lbl')
        }

    @staticmethod
    def batch_collate(data_list):
        batch_dict = {k: [data[k] for data in data_list] for k in data_list[0].keys()}
        batch_size = len(data_list)
        ret = {}

        for key, val in batch_dict.items():
            if key == 'out_file':
                ret[key] = val
                continue
            cnts = [len(v) for v in val]
            data = np.zeros((batch_size, max(cnts), val[0].shape[1]))
            for i, c in enumerate(cnts):
                data[i, :c, :] = val[i]
            data = torch.from_numpy(data).float()
            ret[key] = data
            ret[f'{key}_cnt'] = cnts

        return ret


def match_labels(batch_data):
    """
    Carla semantic lidar sensor generates different point clouds as lidar sensor,
    This function finds the nearst semantic lidar label(ObjTag) for each point in the
    point cloud generated by lidar sensor
    """
    lidars = batch_data['lidar'] # BxNx3
    lidars_cnt = batch_data['lidar_cnt']
    lidars_sem = batch_data['lidar_sem'] # BxMx3
    lidars_sem_cnt = batch_data['lidar_sem_cnt'] # BxMx1

    dists = torch.norm(lidars.unsqueeze(2) - lidars_sem.unsqueeze(1), dim=-1)
    dists_min = dists.min(dim=2)


def load_tensors_to_gpu(batch_dict):
    """
    Load all tensors in batch_dict to gpu
    :param batch_dict: batched data dict
    :return:
    """
    for k, v in batch_dict.items():
        if isinstance(v, torch.Tensor):
            batch_dict[k] = v.cuda()
    return batch_data


if __name__ == "__main__":
    root = "/media/hdd/yuan/koko/data/OPV2V"
    split = 'train'
    lidar_semantic_dir = "additional"
    lidar_range = [-56, -56, -3, 56, 56, 1]
    batch_size = 2
    dataset = LidarDataset(
        root,
        split,
        lidar_semantic_dir,
        lidar_range
    )
    loader = DataLoader(
        dataset, batch_size=batch_size, num_workers=4,
        collate_fn=dataset.batch_collate, drop_last=False
    )

    for batch_data in tqdm.tqdm(loader):
        batch_data = load_tensors_to_gpu(batch_data)
        match_labels(batch_data)